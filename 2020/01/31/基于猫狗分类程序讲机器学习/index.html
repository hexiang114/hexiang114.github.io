<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5"><title>基于猫狗分类程序讲机器学习 | CodeRiver</title><meta name="description" content="基于猫狗分类程序讲机器学习"><meta name="author" content="He"><meta name="copyright" content="He"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin><link rel="preconnect" href="//busuanzi.ibruce.info"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="基于猫狗分类程序讲机器学习"><meta name="twitter:description" content="基于猫狗分类程序讲机器学习"><meta name="twitter:image" content="https://s2.ax1x.com/2020/01/26/1miQ9s.jpg"><meta property="og:type" content="article"><meta property="og:title" content="基于猫狗分类程序讲机器学习"><meta property="og:url" content="http://yoursite.com/2020/01/31/%E5%9F%BA%E4%BA%8E%E7%8C%AB%E7%8B%97%E5%88%86%E7%B1%BB%E7%A8%8B%E5%BA%8F%E8%AE%B2%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><meta property="og:site_name" content="CodeRiver"><meta property="og:description" content="基于猫狗分类程序讲机器学习"><meta property="og:image" content="https://s2.ax1x.com/2020/01/26/1miQ9s.jpg"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>const autoChangeMode = 'false'
var t = Cookies.get("theme");
if (autoChangeMode == '1'){
const isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
const isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
const isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

if (t === undefined){
  if (isLightMode) activateLightMode()
  else if (isDarkMode) activateDarkMode()
  else if (isNotSpecified || hasNoSupport){
    console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
    now = new Date();
    hour = now.getHours();
    isNight = hour < 6 || hour >= 18
    isNight ? activateDarkMode() : activateLightMode()
}
} else if (t == 'light') activateLightMode()
else activateDarkMode()


} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="canonical" href="http://yoursite.com/2020/01/31/%E5%9F%BA%E4%BA%8E%E7%8C%AB%E7%8B%97%E5%88%86%E7%B1%BB%E7%A8%8B%E5%BA%8F%E8%AE%B2%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  bookmark: {
    title: 'Snackbar.bookmark.title',
    message_prev: 'Press',
    message_next: 'to bookmark this page'
  },
  runtime_unit: 'days',
  runtime: true,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  baiduPush: false,
  isHome: false,
  isPost: true
  
}</script><meta name="generator" content="Hexo 4.2.0"></head><body><header> <div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">CodeRiver</a></span><span class="toggle-menu pull_right close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> About</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> List</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/photo/"><i class="fa-fw fa fa-music"></i><span> Photo</span></a></li><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> Movie</span></a></li></ul></div></div></span></div></header><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">Articles</div><div class="length_num">1</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> About</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> List</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/photo/"><i class="fa-fw fa fa-music"></i><span> Photo</span></a></li><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> Movie</span></a></li></ul></div></div></div><div id="mobile-sidebar-toc"><div class="toc_mobile_headline">Catalog</div><div class="sidebar-toc__content"><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#简介"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text">简介</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#须知"><span class="toc_mobile_items-number">2.</span> <span class="toc_mobile_items-text">须知</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#正文"><span class="toc_mobile_items-number">3.</span> <span class="toc_mobile_items-text">正文</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#调用库"><span class="toc_mobile_items-number">3.1.</span> <span class="toc_mobile_items-text">调用库</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#处理文件"><span class="toc_mobile_items-number">3.2.</span> <span class="toc_mobile_items-text">处理文件</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#路径配置"><span class="toc_mobile_items-number">3.2.1.</span> <span class="toc_mobile_items-text">路径配置</span></a></li></ol></li></ol></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#Dropout-50-避免过拟合"><span class="toc_mobile_items-number"></span> <span class="toc_mobile_items-text">Dropout(50%) 避免过拟合</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#装配模型"><span class="toc_mobile_items-number"></span> <span class="toc_mobile_items-text">装配模型</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#对20张图片采用数据源生成"><span class="toc_mobile_items-number"></span> <span class="toc_mobile_items-text">对20张图片采用数据源生成</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#结束"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text">结束</span></a></li></ol></div></div></div><div id="body-wrap"><div id="web_bg" data-type="photo"></div><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true">     </i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#简介"><span class="toc-number">1.</span> <span class="toc-text">简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#须知"><span class="toc-number">2.</span> <span class="toc-text">须知</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#正文"><span class="toc-number">3.</span> <span class="toc-text">正文</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#调用库"><span class="toc-number">3.1.</span> <span class="toc-text">调用库</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#处理文件"><span class="toc-number">3.2.</span> <span class="toc-text">处理文件</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#路径配置"><span class="toc-number">3.2.1.</span> <span class="toc-text">路径配置</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Dropout-50-避免过拟合"><span class="toc-number"></span> <span class="toc-text">Dropout(50%) 避免过拟合</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#装配模型"><span class="toc-number"></span> <span class="toc-text">装配模型</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#对20张图片采用数据源生成"><span class="toc-number"></span> <span class="toc-text">对20张图片采用数据源生成</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#结束"><span class="toc-number">1.</span> <span class="toc-text">结束</span></a></li></ol></div></div></div><main id="content-outer"><div id="top-container" style="background-image: url(https://s2.ax1x.com/2020/01/26/1miQ9s.jpg)"><div id="post-info"><div id="post-title"><div class="posttitle">基于猫狗分类程序讲机器学习</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> Created 2020-01-31<span class="post-meta__separator">|</span><i class="fa fa-history fa-fw" aria-hidden="true"></i> Updated 2020-01-31</time><div class="post-meta-wordcount"><div class="post-meta-pv-cv"><span><i class="fa fa-eye post-meta__icon fa-fw" aria-hidden="true"> </i>Post View:</span><span id="busuanzi_value_page_pv"></span></div></div></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><html><head></head><body><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>本文阐述机器学习实现猫狗图片分类程序流程（因此不会对概念做过多解释），主要目的是使整个代码可复现（毕竟不管学啥，先玩上再说）  </p>
<p> <br>首先还是得夸夸谷歌的<strong>Google Developers</strong>，上面的<a href="https://developers.google.cn/machine-learning/crash-course" target="_blank" rel="noopener">机器学习快速入门教程</a>不说最好懂，但一定是最容易上手的了（毕竟代码都贴到<strong>jupyter notebook</strong>上了）<br>   </p>
<p>如果说你还不知道什么是<strong>jupyter notebook</strong>的话……<br>                        ;             就请自行百度吧 (╯▽╰)╭</p>
<h2 id="须知"><a href="#须知" class="headerlink" title="须知"></a>须知</h2><ul>
<li>文章中的代码都可以在<a href><strong>github</strong></a>中找到  </li>
<li>文章使用的图片源<a href="https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip" target="_blank" rel="noopener">下载</a></li>
<li>作者使用版本为：<ul>
<li>python3.7</li>
<li>tensorflow2.0</li>
</ul>
</li>
<li><u>==文中遇到代码部分都有解释，遇到看不懂的部分请先阅读下方文字==</u></li>
<li>本文不涉及无监督学习</li>
</ul>
<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>那么闲话少说，我们直接进入正题<br>分类算法的概念大家应该都有所了解，我只简单描述一下<br> <br>首先要明确机器学习是一种==概念==而非针对某一问题的==特解==，因此我们训练出的模型具有很强的泛用性，分类算法就是其中一种。</p>
<p>就拿我们本章要训练的猫狗分类模型来说，我们把它原封不动的拿去分类鸟和飞机或者用于识别数字都是完全可行的，甚至准确率都不会受到太大影响（++要知道最重要的是用于训练的数据而非算法，我们在编写机器学习程序的过程中占用篇幅最大的同样是数据处理++）<br> <br>总而言之，分类算法是个==黑盒==，我们学会了猫狗分类就学会了其它的分类方法</p>
<h3 id="调用库"><a href="#调用库" class="headerlink" title="调用库"></a>调用库</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line"></span><br><span class="line">from tensorflow.keras import layers</span><br><span class="line">from tensorflow.keras import Model</span><br><span class="line"></span><br><span class="line">from tensorflow.keras.optimizers import RMSprop</span><br><span class="line"></span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from tensorflow.keras.preprocessing.image import ImageDataGenerat</span><br><span class="line"></span><br><span class="line">import tensorflow as tf</span><br><span class="line">from tensorflow import keras</span><br></pre></td></tr></tbody></table></figure></div>

<h3 id="处理文件"><a href="#处理文件" class="headerlink" title="处理文件"></a>处理文件</h3><p>==下面是枯燥的配置文件时间，若不打算边阅读教程边写代码的读者可以跳过该部分==<br>首先<a href="https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip" target="_blank" rel="noopener">下载</a>和==解压==须知中给出的猫狗图片包</p>
<h4 id="路径配置"><a href="#路径配置" class="headerlink" title="路径配置"></a>路径配置</h4><p><a href="https://imgchr.com/i/1u2PJA" target="_blank" rel="noopener"><img alt="1u2PJA.md.jpg" data-src="https://s2.ax1x.com/2020/01/27/1u2PJA.md.jpg" class="lazyload"></a></p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">base_dir = 'data/cats_and_dogs_filtered'</span><br><span class="line"></span><br><span class="line">train_dir = os.path.join(base_dir, 'data/cats_and_dogs_filtered')</span><br><span class="line">validation_dir = os.path.join(base_dir, 'validation')</span><br></pre></td></tr></tbody></table></figure></div>
<p>此处的路径配置如上图所示应该是很清楚的，唯一的疑问可能在<code>os.path.join()</code>中  </p>
<p>用一句话来解释，就是把括号中的两个路径拼接在一起  </p>
<p><code>data/cats_and_dogs_filtered + train = data/cats_and_dogs_filtered/train</code><br> <br>接下来继续配置路径</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">train_cats_dir = os.path.join(train_dir, 'cats')</span><br><span class="line">train_dogs_dir = os.path.join(train_dir, 'dogs')</span><br><span class="line"></span><br><span class="line">validation_cats_dir = os.path.join(validation_dir, 'cats')</span><br><span class="line">validation_dogs_dir = os.path.join(validation_dir, 'dogs')</span><br><span class="line">```  </span><br><span class="line">   </span><br><span class="line">若此处对路径还有疑惑可以`print`上文配置好的路径检查详细信息（++若存在莫名错误可以先使用绝对路径编译通过，从而继续阅读++）</span><br><span class="line">#### 读取文件夹</span><br></pre></td></tr></tbody></table></figure></div>
<p>train_cat_fnames = os.listdir(train_cats_dir)<br>train_cat_fnames.sort()<br>train_dog_fnames = os.listdir(train_dogs_dir)<br>train_dog_fnames.sort()</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">这里我们读取上文配置好的`train_cats_dir`和`train_dogs_dir`里的文件名，如果不明白请尝试`print`  </span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">善用`print`可以解决很多阅读问题，比如打印`.type` `len()` `[i]` `.shape()`等，拿上面的代码举例  </span><br><span class="line"></span><br><span class="line">我们`print`猫文件`train_cats_dir`的前10个元素和总图片数</span><br><span class="line"></span><br><span class="line">[![1uhP78.md.jpg](https://s2.ax1x.com/2020/01/27/1uhP78.md.jpg)](https://imgchr.com/i/1uhP78)</span><br><span class="line"></span><br><span class="line">那么至此杂七杂八的文件配置工作就完成了！  </span><br><span class="line">让我们开始真正的机器学习工作！</span><br><span class="line"></span><br><span class="line">### 预处理数据</span><br><span class="line">现实世界的数据一般是不完整的、有噪声的和不一致的，所以我们要对传入模型的数据进行预处理  </span><br><span class="line"></span><br><span class="line">#### 数据增强</span><br><span class="line">很多时候我们会遇到数据量不够或者数据重复使用次数太多的情况，==数据增强==就是为这种情况服务的  </span><br><span class="line">![1K4Rcd.png](https://s2.ax1x.com/2020/01/28/1K4Rcd.png)</span><br><span class="line"></span><br><span class="line">如上图所示，我们对猫进行了随机拉伸，缩放，翻转和平移等操作，使得我们的训练量增加了，但也带来了过拟合的风险  </span><br><span class="line"></span><br><span class="line">这时就该请出Dropout函数了，在紧挨着的下一节中我们还会提到他，并对过拟合问题作出解答  </span><br><span class="line"></span><br><span class="line">#### 规范数据</span><br><span class="line">至于其他的部分没有什么好说的，由于像素值处在 **[0,255]** 的范围内，因此在`ImageDataGenerator`中我们把它规范化到 **[0,1]** 的区间，其余参数如英文描述所示，分别代表（旋转角度，水平竖直拉伸，裁剪，缩放，水平翻转）等数据增强方法</span><br></pre></td></tr></tbody></table></figure></div>
<p>train_datagen = ImageDataGenerator(<br>    rescale = 1./255,<br>    rotation_range = 40,<br>    width_shift_range = 0.2,<br>    height_shift_range = 0.2,<br>    shear_range = 0.2,<br>    zoom_range = 0.2,<br>    horizontal_flip = True<br>)<br>val_datagen = ImageDataGenerator(rescale = 1./255)</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">随后我们规范输入图片大小，==以及相关模型参数==</span><br></pre></td></tr></tbody></table></figure></div>
<p>train_generator = train_datagen.flow_from_directory(<br>            train_dir,<br>            target_size = (150, 150),<br>            batch_size = 20,<br>            class_mode = ‘binary’)</p>
<p>validation_generator = val_datagen.flow_from_directory(<br>            validation_dir,<br>            target_size = (150, 150),<br>            batch_size = 20,<br>            class_mode = ‘binary’)</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line">### 构建神经网络</span><br><span class="line">神经网络配置如下</span><br><span class="line">![1KbyqJ.jpg](https://s2.ax1x.com/2020/01/28/1KbyqJ.jpg)  </span><br><span class="line"></span><br><span class="line">没错，看到那个熟悉的面孔了吗，Dropout函数闪亮登场，但作为一个如此重要的函数他的原理却简单的离谱</span><br><span class="line">![1KLVAA.jpg](https://s2.ax1x.com/2020/01/28/1KLVAA.jpg)   </span><br><span class="line">那我们来解释一下：这里的 **Dropout(0.5)** 代表的意思是隐藏层删一半，解释完了  </span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">当然不会简单到这种地步，这里的步骤如下：</span><br><span class="line">1. 神经网络向前传播的过程中随机隐藏一半的神经元</span><br><span class="line">2. 其余神经元计算完损失反向传播后权重得到更新</span><br><span class="line">3. 恢复被隐藏的神经元</span><br><span class="line">4. 重复执行上述步骤  </span><br><span class="line"></span><br><span class="line">是不是有一点明白了，如果还是难以理解可以换一个思路，我们每次只随机选一半的神经元参与训练，至于是哪一半则完全随机  </span><br><span class="line"></span><br><span class="line">那么 **Dropout** 的话题就告一段落，我们重新梳理一下关于神经网络的事情  </span><br><span class="line"></span><br><span class="line">卷积神经网络 **（Convolutional Neural Networks）** 简称CNN，首先还是来理解卷积层的含义  </span><br><span class="line"></span><br><span class="line">虽说不讲的太深入，但是我认为最基本的原理还是要了解的，所以下文会提到一些关于卷积层的数学方面的东西（但不要紧张，不会很难，毕竟作者数学也不怎么好） </span><br><span class="line"></span><br><span class="line">![1QtthT.jpg](https://s2.ax1x.com/2020/01/29/1QtthT.jpg)</span><br><span class="line">![1QtZAP.png](https://s2.ax1x.com/2020/01/29/1QtZAP.png)</span><br><span class="line">先整两张市面上最常见的CNN图，看不懂吧，那就对了  </span><br><span class="line"></span><br><span class="line">##### 输入层</span><br><span class="line">![1QtTEt.png](https://s2.ax1x.com/2020/01/29/1QtTEt.png)  </span><br><span class="line">现在注意我圈出来的部分，这一部分对应输入层 **（input）**，图片从这里进入神经网络 ，那么为什么上面只有32x32x1这一个矩阵而下边是224x224x3的三个矩阵呢  </span><br><span class="line"></span><br><span class="line">这里很好理解，首先32x32和224x224是图片大小，其次第一张图是一张灰度图所以我们称为有一个**feature map**（一个矩阵），而下面那张图是一张彩色的，彩色图具有（R，G，B）三个**feature map**（三个矩阵，或者深度为3）</span><br><span class="line"></span><br><span class="line">##### 卷积层</span><br><span class="line">先来讲讲卷积层的作用  </span><br><span class="line">我们在输入层中输入的是一张图片的全部数据，它具有相当多的特征和干扰，因此在最终利用特征得出结论前我们需要筛选和提取出最重要的部分，这就是卷积层所做的工作</span><br><span class="line"></span><br><span class="line">##==！！！！！！！（待插入两张图片，猫正常-猫锐化）==</span><br><span class="line"></span><br><span class="line">![1QBuad.png](https://s2.ax1x.com/2020/01/29/1QBuad.png)</span><br><span class="line">现在来关注这一部分</span><br><span class="line">![1QBQPI.jpg](https://s2.ax1x.com/2020/01/29/1QBQPI.jpg)</span><br><span class="line">从直观上来讲就是我们用一个3x3的矩阵和原矩阵中的一部分对应相乘求和，然后依次移动矩阵 ==（没看懂请注意图片右上角公式）==，由此我们能得到一张新图</span><br><span class="line"></span><br><span class="line">##==！！！！！！！（待插入图片）==</span><br><span class="line"></span><br><span class="line">卷积核，算子，拉普拉斯算法</span><br><span class="line">锐化其实和边缘检测如出一辙，从微分的角度来看，灰度变化越大的地方，微分值也越大</span><br><span class="line">![1Qs6L8.jpg](https://s2.ax1x.com/2020/01/29/1Qs6L8.jpg)</span><br><span class="line"></span><br><span class="line">回顾一下微分的算法（求差值）</span><br><span class="line">![1QsbeU.jpg](https://s2.ax1x.com/2020/01/29/1QsbeU.jpg)</span><br><span class="line"></span><br><span class="line">二阶微分同理</span><br><span class="line">![1QyPeO.jpg](https://s2.ax1x.com/2020/01/29/1QyPeO.jpg)</span><br><span class="line"></span><br><span class="line">引出拉普拉斯算法</span><br><span class="line">![1QyFTe.jpg](https://s2.ax1x.com/2020/01/29/1QyFTe.jpg)</span><br><span class="line"></span><br><span class="line">注意关注最下边那行，如果我们把它化成一个坐标系就应该是</span><br><span class="line">![1QyQ0S.jpg](https://s2.ax1x.com/2020/01/29/1QyQ0S.jpg)</span><br><span class="line"></span><br><span class="line">发现规律了吧，这就是卷积核的本质</span><br><span class="line"></span><br><span class="line">本段图片转自[知乎-蒋竺波</span><br><span class="line">](https://zhuanlan.zhihu.com/p/30994790)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">那么源码放送</span><br></pre></td></tr></tbody></table></figure></div>
<p>img_input = layers.Input(shape=(150, 150, 3))</p>
<p>x = layers.Conv2D(16, 3, activation=’relu’)(img_input)<br>x = layers.MaxPooling2D(2)(x)<br>x = layers.Conv2D(32, 3, activation=’relu’)(x)<br>x = layers.MaxPooling2D(2)(x)<br>x = layers.Conv2D(64, 3, activation=’relu’)(x)<br>x = layers.MaxPooling2D(2)(x)</p>
<p>x = layers.Flatten()(x)<br>x = layers.Dense(512, activation=’relu’)(x)</p>
<h1 id="Dropout-50-避免过拟合"><a href="#Dropout-50-避免过拟合" class="headerlink" title="Dropout(50%) 避免过拟合"></a>Dropout(50%) 避免过拟合</h1><p>x = layers.Dropout(0.5)(x)</p>
<p>output = layers.Dense(1, activation=’sigmoid’)(x)</p>
<h1 id="装配模型"><a href="#装配模型" class="headerlink" title="装配模型"></a>装配模型</h1><p>model = Model(img_input, output)</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">可以看出，代码步骤与表中完全一致，从`img_input`起，每一层分别作为下一层的输入，在卷积层中我们使用的激活函数是`relu`  </span><br><span class="line"></span><br><span class="line">三次卷积后使用`Flatten`将矩阵展开为一维向量，进入全联接层，调用`Dopout（）`函数，最终得到输出</span><br><span class="line"></span><br><span class="line">最后我们从入口 `img_input`到出口`output`装配模型`model`</span><br><span class="line"></span><br><span class="line">当我们想检查模型详细情况时可以调用函数`.summary()`</span><br></pre></td></tr></tbody></table></figure></div>
<p>model.summary()</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">![18pJqs.png](https://s2.ax1x.com/2020/01/31/18pJqs.png)</span><br><span class="line"></span><br><span class="line">### 训练模型</span><br><span class="line">在真正训练模型前我们还需要配置一些训练属性</span><br><span class="line">##### 编译模型</span><br></pre></td></tr></tbody></table></figure></div>
<p>model.compile(loss=’binary_crossentropy’,<br>              optimizer=RMSprop(lr=0.001),<br>              metrics=[‘acc’])    # metrics 评价函数用于评估当前训练模型的性能</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">这里主要是对优化器`optimizer`（梯度下降算法），损失函数（`loss`），评价函数的配置</span><br><span class="line"></span><br><span class="line">此处我们使用的评价函数是**acc** ，因为我们只有猫和狗两种样本且分布比较平均，当样本分布不平均时**acc** 这种评价方法就未必有效了  </span><br><span class="line"></span><br><span class="line">比方说在检测垃圾邮件中，我们将大量垃圾样本和少量准确样本放在一起时为了得到更好评价，训练中可能将所有邮件都判定为垃圾邮件，如此得到的高准确率模型并没有意义  </span><br><span class="line"></span><br><span class="line">##### 训练</span><br><span class="line">废话少说，直接放代码</span><br></pre></td></tr></tbody></table></figure></div>
<p>history = model.fit_generator(<br>    train_generator,<br>    steps_per_epoch = 100,<br>    epochs = 30,<br>    validation_data = validation_generator,<br>    validation_steps = 50,<br>    verbose = 2) # 日志显示 0 不输出 1 输出进度条 2 每个epoch输出</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">训练可能要花个几分钟</span><br><span class="line"></span><br><span class="line">训练结束后可以调用`matplotlib`查看曲线图</span><br></pre></td></tr></tbody></table></figure></div>
<p>acc = history.history[‘acc’]<br>val_acc = history.history[‘val_acc’]<br>loss = history.history[‘loss’]<br>val_loss = history.history[‘val_loss’]</p>
<p>epochs = range(len(acc)) # 30</p>
<p>plt.plot(epochs, acc)<br>plt.plot(epochs, val_acc)<br>plt.title(‘ACC’)</p>
<p>plt.figure()</p>
<p>plt.plot(epochs, loss)<br>plt.plot(epochs, val_loss)<br>plt.title(‘LOSS’)</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">![18ACmF.png](https://s2.ax1x.com/2020/01/31/18ACmF.png)</span><br><span class="line"></span><br><span class="line">### 保存和调用</span><br><span class="line">##### 保存</span><br></pre></td></tr></tbody></table></figure></div>
<p>model.save(‘my_model.h5’)</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">##### 读取</span><br></pre></td></tr></tbody></table></figure></div>
<p>new_model = keras.models.load_model(‘my_model.h5’)</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">##### 测试</span><br><span class="line">现在可以试试我们的模型效果如何了！</span><br><span class="line"></span><br><span class="line">重复前文配置地址到预处理步骤，创建一个新的测试集(此处图片建议自行从Google搜集)</span><br></pre></td></tr></tbody></table></figure></div>
<p>test_dir = os.path.join(base_dir, ‘testcat’)<br>new_train_datagen = ImageDataGenerator(rescale = 1./255)</p>
<h1 id="对20张图片采用数据源生成"><a href="#对20张图片采用数据源生成" class="headerlink" title="对20张图片采用数据源生成"></a>对20张图片采用数据源生成</h1><p>new_train_generator = new_train_datagen.flow_from_directory(<br>            test_dir,<br>            target_size = (150, 150),<br>            batch_size = 1,<br>            class_mode = ‘binary’)</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">预测测试集</span><br></pre></td></tr></tbody></table></figure></div>
<p>my_predict = new_model.predict(new_train_generator)</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">对预测结果做一个输出</span><br></pre></td></tr></tbody></table></figure></div>
<p>i = 1<br>for each in my_predict:<br>    print(i,’: ‘, end = ‘’)<br>    i += 1<br>    if each >= 9.0000000e-01:<br>        print(‘狗’,each)<br>    else:<br>        print(‘猫’,each)</p>
<p>```<br><a href="https://s2.ax1x.com/2020/01/31/18Az4A.png" target="_blank" rel="noopener" data-fancybox="group" data-caption="18Az4A.png" class="fancybox"><img alt="18Az4A.png" title="18Az4A.png" data-src="https://s2.ax1x.com/2020/01/31/18Az4A.png" class="lazyload"></a></p>
<h2 id="结束"><a href="#结束" class="headerlink" title="结束"></a>结束</h2><p>那么至此我们已经走完了整个程序流程，其中对我觉得重要的部分进行了深度的讲解，其余部分则一笔带过 </p>
<p>最后依然要说，机器学习是很多学科交汇的桥梁，绝不是闭门造车就能登堂入室的，一定要了解更多其他方面的知识，比如此次程序用到的计算机视觉中的图片处理方法也是机器学习中最常见结合的部分</p>
<p>此处给出一些推荐文章和论文</p>
<ul>
<li><p><a href="https://zhuanlan.zhihu.com/p/24339995" target="_blank" rel="noopener">知乎-机器学习为什么这么有趣</a><br>  该系列很适合入门，上面放出的是国内翻译的中文版本，此处<a href="https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471" target="_blank" rel="noopener">原文</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/c_141391545" target="_blank" rel="noopener">知乎-蒋竺波</a><br>  作者文风很幽默，配图也非常清晰易懂，对半懂不懂的同学有奇效</p>
</li>
<li><p><a href="http://xueshu.baidu.com/usercenter/paper/show?paperid=d84e06a8356a320f043938b9f8515397&site=xueshu_se" target="_blank" rel="noopener">Histograms of Oriented Gradients for Human Detection</a><br>  关于<strong>方向梯度直方图(HOG)</strong> 的论文，该方法被广泛应用于人像识别</p>
</li>
</ul>
<p>这是笔者的第一篇博客，如有任何不足之处还请直接指出，每一条意见对我来说都十分宝贵！</p>
</body></html></div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">He</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://yoursite.com/2020/01/31/%E5%9F%BA%E4%BA%8E%E7%8C%AB%E7%8B%97%E5%88%86%E7%B1%BB%E7%A8%8B%E5%BA%8F%E8%AE%B2%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">http://yoursite.com/2020/01/31/%E5%9F%BA%E4%BA%8E%E7%8C%AB%E7%8B%97%E5%88%86%E7%B1%BB%E7%A8%8B%E5%BA%8F%E8%AE%B2%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://s2.ax1x.com/2020/01/26/1miQ9s.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><a class="reward-button button--primary button--animated"> <i class="fa fa-qrcode"></i> Donate<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="lazyload post-qr-code__img" src="/img/wechat.jpg" alt="微信"><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="lazyload post-qr-code__img" src="/img/alipay.jpg" alt="支付寶"><div class="post-qr-code__desc">支付寶</div></li></ul></div></a></div><nav class="pagination_post" id="pagination"></nav></div></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2020 By He</div><div class="framework-info"><span>Driven </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="Read Mode"></i><i class="fa fa-plus" id="font_plus" title="Increase font size"></i><i class="fa fa-minus" id="font_minus" title="Decrease font size"></i><i class="darkmode fa fa-moon-o" id="darkmode" title="Dark Mode"></i></div><div id="rightside-config-show"><div id="rightside_config" title="Setting"><i class="fa fa-cog" aria-hidden="true"></i></div><i class="fa fa-list-ul close" id="mobile-toc-button" title="Table of Contents" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="Back to top" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async=""></script></body></html>